{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing CART and MIO methods to create decision trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages needed for CART and MIO methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tree as miptree\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.tree import export_graphviz\n",
    "import pydot\n",
    "from sklearn import tree\n",
    "\n",
    "\n",
    "import time\n",
    "from os import path\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function to convert data into binary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_features(array):\n",
    "    output = array.copy()\n",
    "    for i in array.index:\n",
    "        if 0 < array.num[i]:\n",
    "            output.num[i] = 1\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "timelimit = 600\n",
    "seed = 42\n",
    "\n",
    "min_samples_split=2\n",
    "alpha = [0, 0.01, 0.1]\n",
    "depth = [2, 3]\n",
    "seeds = [37, 42]\n",
    "\n",
    "train_ratio = 0.5\n",
    "val_ratio = 0.25\n",
    "test_ratio = 0.25\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import and manipulate data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "heart_disease = fetch_ucirepo(id=45)\n",
    "x = heart_disease.data.features\n",
    "y = heart_disease.data.targets\n",
    "# Normalize x data to be between 0 and 1 for each feature\n",
    "x = (x - x.min()) / (x.max() - x.min())\n",
    "# remove NaN values from dataset\n",
    "x = x.dropna(axis=0)\n",
    "y = y.iloc[x.index]\n",
    "#Create random samples of data\n",
    "x1 = x.sample(n=75, random_state=seeds[0])\n",
    "x2 = x.sample(n=75, random_state=seeds[1])\n",
    "# Create random samples of data for y\n",
    "y1 = y.sample(n=75, random_state=seeds[0])\n",
    "y2 = y.sample(n=75, random_state=seeds[1])\n",
    "# Create list of datasets\n",
    "datasets = ['Heart failure']\n",
    "# Define features\n",
    "features = x.columns\n",
    "# Convert to numpy array\n",
    "x1 = x1.to_numpy()\n",
    "x2 = x2.to_numpy()\n",
    "x = x.to_numpy()\n",
    "# Convert to pandas dataframe\n",
    "y1 = binary_features(y1)\n",
    "y1 = y1.values.flatten()\n",
    "y2 = binary_features(y2)\n",
    "y2 = y2.values.flatten()\n",
    "y = binary_features(y)\n",
    "y = y.values.flatten()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create or load table\n",
    "res_sk = pd.DataFrame(columns=['instance', 'depth', 'seed', 'train_acc', 'val_acc', 'test_acc', 'train_time'])\n",
    "if path.isfile('./res/oct.csv'):\n",
    "    res_oct = pd.read_csv('./res/oct.csv')\n",
    "else:\n",
    "    res_oct = pd.DataFrame(columns=['instance', 'depth', 'alpha', 'seed', \n",
    "                                    'train_acc', 'val_acc', 'test_acc', 'train_time', 'gap'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# x1 and y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heart failure cart-d2-a0-s37 train acc: 0.972972972972973 val acc: 0.7368421052631579\n",
      "Heart failure cart-d2-a0.01-s37 train acc: 0.972972972972973 val acc: 0.7368421052631579\n",
      "Heart failure cart-d2-a0.1-s37 train acc: 0.8918918918918919 val acc: 0.6842105263157895\n",
      "Heart failure cart-d2-a0-s42 train acc: 0.8648648648648649 val acc: 0.631578947368421\n",
      "Heart failure cart-d2-a0.01-s42 train acc: 0.8648648648648649 val acc: 0.631578947368421\n",
      "Heart failure cart-d2-a0.1-s42 train acc: 0.8108108108108109 val acc: 0.631578947368421\n",
      "Heart failure cart-d3-a0-s37 train acc: 0.972972972972973 val acc: 0.7368421052631579\n",
      "Heart failure cart-d3-a0.01-s37 train acc: 0.972972972972973 val acc: 0.7368421052631579\n",
      "Heart failure cart-d3-a0.1-s37 train acc: 0.8918918918918919 val acc: 0.6842105263157895\n",
      "Heart failure cart-d3-a0-s42 train acc: 0.918918918918919 val acc: 0.631578947368421\n",
      "Heart failure cart-d3-a0.01-s42 train acc: 0.918918918918919 val acc: 0.631578947368421\n",
      "Heart failure cart-d3-a0.1-s42 train acc: 0.8108108108108109 val acc: 0.631578947368421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cg/224y42wn06n9c1r1y31_yvrc0000gn/T/ipykernel_60487/2288598133.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  res_sk = res_sk._append(row, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "#CART\n",
    "for data in datasets:\n",
    "    for d in depth:\n",
    "        for s in seeds:\n",
    "            x_train, x_test, y_train, y_test = train_test_split(x1, y1, test_size=1-train_ratio, random_state=s)\n",
    "            x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, \n",
    "                                                            test_size=test_ratio/(test_ratio+val_ratio), random_state=s)\n",
    "            for a in alpha:\n",
    "                clf = tree.DecisionTreeClassifier(max_depth=d, min_samples_split=2, ccp_alpha=a)\n",
    "                tick = time.time()\n",
    "                clf.fit(x_train, y_train)\n",
    "                tock = time.time()\n",
    "                train_time = tock - tick\n",
    "                train_acc = accuracy_score(y_train, clf.predict(x_train))\n",
    "                val_acc = accuracy_score(y_val, clf.predict(x_val))\n",
    "                test_acc = accuracy_score(y_test, clf.predict(x_test))\n",
    "                print(data, 'cart-d{}-a{}-s{}'.format(d,a,s), 'train acc:', train_acc, 'val acc:', val_acc)\n",
    "                row = {'instance':data, 'depth':d, 'seed':s, 'train_acc':train_acc, \n",
    "                    'val_acc':val_acc, 'test_acc':test_acc, 'train_time':train_time}\n",
    "                res_sk = res_sk._append(row, ignore_index=True)\n",
    "                res_sk.to_csv('./res/sk.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create tree using miptree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2024-10-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cg/224y42wn06n9c1r1y31_yvrc0000gn/T/ipykernel_60487/3369902663.py:28: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  res_oct = res_oct._append(row, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heart failure oct-d2-a0-s37 train acc: 0.972972972972973 val acc: 0.7894736842105263 train_time: 9.555217981338501 gap: 0.0\n",
      "Heart failure oct-d2-a0.01-s37 train acc: 0.972972972972973 val acc: 0.7368421052631579 train_time: 3.157528877258301 gap: 0.0\n",
      "Heart failure oct-d2-a0.1-s37 train acc: 0.8918918918918919 val acc: 0.6842105263157895 train_time: 2.6345627307891846 gap: 0.0\n",
      "Heart failure oct-d2-a0-s42 train acc: 0.918918918918919 val acc: 0.7894736842105263 train_time: 6.175588846206665 gap: 0.0\n",
      "Heart failure oct-d2-a0.01-s42 train acc: 0.918918918918919 val acc: 0.7894736842105263 train_time: 5.092710971832275 gap: 0.0\n",
      "Heart failure oct-d2-a0.1-s42 train acc: 0.8108108108108109 val acc: 0.6842105263157895 train_time: 7.619994163513184 gap: 0.0\n",
      "Heart failure oct-d3-a0-s37 train acc: 1.0 val acc: 0.7894736842105263 train_time: 5.988437175750732 gap: 0.0\n",
      "Heart failure oct-d3-a0.01-s37 train acc: 1.0 val acc: 0.7368421052631579 train_time: 19.434585094451904 gap: 0.0\n",
      "Heart failure oct-d3-a0.1-s37 train acc: 0.8918918918918919 val acc: 0.6842105263157895 train_time: 2.434237241744995 gap: 0.0\n",
      "Heart failure oct-d3-a0-s42 train acc: 1.0 val acc: 0.5789473684210527 train_time: 80.65871477127075 gap: 0.0\n",
      "Heart failure oct-d3-a0.01-s42 train acc: 1.0 val acc: 0.7368421052631579 train_time: 273.094309091568 gap: 0.0\n",
      "Heart failure oct-d3-a0.1-s42 train acc: 0.8108108108108109 val acc: 0.631578947368421 train_time: 91.6125910282135 gap: 0.0\n"
     ]
    }
   ],
   "source": [
    "for data in datasets:\n",
    "    for d in depth:\n",
    "        for s in seeds:\n",
    "            # data splition\n",
    "            x_train, x_test, y_train, y_test = train_test_split(x1, y1, test_size=1-train_ratio, random_state=s)\n",
    "            x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, \n",
    "                                                            test_size=test_ratio/(test_ratio+val_ratio), random_state=s)\n",
    "            for a in alpha:\n",
    "                # oct\n",
    "                row = res_oct[(res_oct['instance'] == data) & (res_oct['depth'] == d) & \n",
    "                              (res_oct['alpha'] == a) & (res_oct['seed'] == s)]\n",
    "                if len(row):\n",
    "                    print(data, 'oct-d{}-a{}'.format(row['depth'].values[0],row['alpha'].values[0]),\n",
    "                          'train acc:', row['train_acc'].values[0], 'val acc:', row['val_acc'].values[0],\n",
    "                          'gap:', row['gap'].values[0])\n",
    "                else:\n",
    "                    octree = miptree.optimalDecisionTreeClassifier(max_depth=d, min_samples_split=2, alpha=a, warmstart=True,\n",
    "                                                                   timelimit=timelimit, output=False)\n",
    "                    tick = time.time()\n",
    "                    octree.fit(x_train, y_train)\n",
    "                    tock = time.time()\n",
    "                    train_time = tock - tick\n",
    "                    train_acc = accuracy_score(y_train, octree.predict(x_train))\n",
    "                    val_acc = accuracy_score(y_val, octree.predict(x_val))\n",
    "                    test_acc = accuracy_score(y_test, octree.predict(x_test))\n",
    "                    row = {'instance':data, 'depth':d, 'alpha':a, 'seed':s, 'train_acc':train_acc, 'val_acc':val_acc,\n",
    "                           'test_acc':test_acc, 'train_time':train_time, 'gap':octree.optgap}\n",
    "                    res_oct = res_oct._append(row, ignore_index=True)\n",
    "                    res_oct.to_csv('./res/oct.csv', index=False)\n",
    "                    print(data, 'oct-d{}-a{}-s{}'.format(d,a,s), \n",
    "                          'train acc:', train_acc, 'val acc:', val_acc, 'train_time:', train_time, 'gap:', octree.optgap)\n",
    "                    #print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heart failure cart-d2-a0 train acc: 0.831081081081081 val acc: 0.7837837837837838\n",
      "Heart failure cart-d2-a0.01 train acc: 0.831081081081081 val acc: 0.7837837837837838\n",
      "Heart failure cart-d2-a0.1 train acc: 0.7972972972972973 val acc: 0.7432432432432432\n",
      "Heart failure cart-d2-a0 train acc: 0.8243243243243243 val acc: 0.6621621621621622\n",
      "Heart failure cart-d2-a0.01 train acc: 0.8243243243243243 val acc: 0.6621621621621622\n",
      "Heart failure cart-d2-a0.1 train acc: 0.7972972972972973 val acc: 0.6621621621621622\n",
      "Heart failure cart-d3-a0 train acc: 0.8851351351351351 val acc: 0.8108108108108109\n",
      "Heart failure cart-d3-a0.01 train acc: 0.8851351351351351 val acc: 0.8108108108108109\n",
      "Heart failure cart-d3-a0.1 train acc: 0.7972972972972973 val acc: 0.7432432432432432\n",
      "Heart failure cart-d3-a0 train acc: 0.8716216216216216 val acc: 0.6891891891891891\n",
      "Heart failure cart-d3-a0.01 train acc: 0.8716216216216216 val acc: 0.7027027027027027\n",
      "Heart failure cart-d3-a0.1 train acc: 0.7972972972972973 val acc: 0.6621621621621622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cg/224y42wn06n9c1r1y31_yvrc0000gn/T/ipykernel_60487/2365071507.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  res_sk = res_sk._append(row, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "#CART\n",
    "for data in datasets:\n",
    "    for d in depth:\n",
    "        for s in seeds:\n",
    "            x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=1-train_ratio, random_state=s)\n",
    "            x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, \n",
    "                                                            test_size=test_ratio/(test_ratio+val_ratio), random_state=s)\n",
    "            for a in alpha:\n",
    "                clf = tree.DecisionTreeClassifier(max_depth=d, min_samples_split=2, ccp_alpha=a)\n",
    "                tick = time.time()\n",
    "                clf.fit(x_train, y_train)\n",
    "                tock = time.time()\n",
    "                train_time = tock - tick\n",
    "                train_acc = accuracy_score(y_train, clf.predict(x_train))\n",
    "                val_acc = accuracy_score(y_val, clf.predict(x_val))\n",
    "                test_acc = accuracy_score(y_test, clf.predict(x_test))\n",
    "                print(data, 'cart-d{}-a{}'.format(d,a), 'train acc:', train_acc, 'val acc:', val_acc)\n",
    "                row = {'instance':data, 'depth':d, 'seed':s, 'train_acc':train_acc, \n",
    "                    'val_acc':val_acc, 'test_acc':test_acc, 'train_time':train_time}\n",
    "                res_sk = res_sk._append(row, ignore_index=True)\n",
    "                res_sk.to_csv('./res/sk.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cg/224y42wn06n9c1r1y31_yvrc0000gn/T/ipykernel_60487/3078627575.py:29: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  res_oct = res_oct._append(row, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heart failure oct-d2-a0-s37 train acc: 0.8513513513513513 val acc: 0.7702702702702703 train_time: 455.47877192497253 gap: 0.0\n",
      "Heart failure oct-d2-a0.01-s37 train acc: 0.8513513513513513 val acc: 0.7702702702702703 train_time: 585.7548499107361 gap: 0.0\n",
      "Heart failure oct-d2-a0.1-s37 train acc: 0.7972972972972973 val acc: 0.7432432432432432 train_time: 214.47342205047607 gap: 0.0\n",
      "Heart failure oct-d2-a0-s42 train acc: 0.8513513513513513 val acc: 0.7027027027027027 train_time: 213.9971420764923 gap: 0.0\n",
      "Heart failure oct-d2-a0.01-s42 train acc: 0.8513513513513513 val acc: 0.6621621621621622 train_time: 436.1121709346771 gap: 0.0\n",
      "Heart failure oct-d2-a0.1-s42 train acc: 0.7972972972972973 val acc: 0.6621621621621622 train_time: 394.01096510887146 gap: 0.0\n",
      "Heart failure oct-d3-a0-s37 train acc: 0.9054054054054054 val acc: 0.8243243243243243 train_time: 601.0050699710846 gap: 0.9999999999999999\n",
      "Heart failure oct-d3-a0.01-s37 train acc: 0.8851351351351351 val acc: 0.8108108108108109 train_time: 600.409569978714 gap: 0.919573575249774\n",
      "Heart failure oct-d3-a0.1-s37 train acc: 0.7972972972972973 val acc: 0.7432432432432432 train_time: 600.540549993515 gap: 0.5564304461942217\n",
      "Heart failure oct-d3-a0-s42 train acc: 0.8918918918918919 val acc: 0.6621621621621622 train_time: 600.9606239795685 gap: 1.0\n",
      "Heart failure oct-d3-a0.01-s42 train acc: 0.8851351351351351 val acc: 0.7297297297297297 train_time: 600.4494559764862 gap: 0.90625\n",
      "Heart failure oct-d3-a0.1-s42 train acc: 0.7972972972972973 val acc: 0.6621621621621622 train_time: 600.5297360420227 gap: 0.48717948717948717\n"
     ]
    }
   ],
   "source": [
    "# OCT\n",
    "for data in datasets:\n",
    "    for d in depth:\n",
    "        for s in seeds:\n",
    "            # data splition\n",
    "            x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=1-train_ratio, random_state=s)\n",
    "            x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, \n",
    "                                                            test_size=test_ratio/(test_ratio+val_ratio), random_state=s)\n",
    "            for a in alpha:\n",
    "                # oct\n",
    "                row = res_oct[(res_oct['instance'] == data) & (res_oct['depth'] == d) & \n",
    "                              (res_oct['alpha'] == a) & (res_oct['seed'] == s)]\n",
    "                if len(row):\n",
    "                    print(data, 'oct-d{}-a{}'.format(row['depth'].values[0],row['alpha'].values[0]),\n",
    "                          'train acc:', row['train_acc'].values[0], 'val acc:', row['val_acc'].values[0],\n",
    "                          'gap:', row['gap'].values[0])\n",
    "                else:\n",
    "                    octree = miptree.optimalDecisionTreeClassifier(max_depth=d, min_samples_split=2, alpha=a, warmstart=True,\n",
    "                                                                   timelimit=timelimit, output=False)\n",
    "                    tick = time.time()\n",
    "                    octree.fit(x_train, y_train)\n",
    "                    tock = time.time()\n",
    "                    train_time = tock - tick\n",
    "                    train_acc = accuracy_score(y_train, octree.predict(x_train))\n",
    "                    val_acc = accuracy_score(y_val, octree.predict(x_val))\n",
    "                    test_acc = accuracy_score(y_test, octree.predict(x_test))\n",
    "                    row = {'instance':data, 'depth':d, 'alpha':a, 'seed':s, 'train_acc':train_acc, 'val_acc':val_acc,\n",
    "                           'test_acc':test_acc, 'train_time':train_time, 'gap':octree.optgap}\n",
    "                    res_oct = res_oct._append(row, ignore_index=True)\n",
    "                    res_oct.to_csv('./res/oct.csv', index=False)\n",
    "                    print(data, 'oct-d{}-a{}-s{}'.format(d,a,s), \n",
    "                          'train acc:', train_acc, 'val acc:', val_acc, 'train_time:', train_time, 'gap:', octree.optgap)\n",
    "                    #print(row)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c0272e05230dc63e6e03211cff96ee0cfa8f6b88f59df09567db12e0aadba25f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
